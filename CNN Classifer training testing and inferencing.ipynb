{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c53rBwRYwbVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train, save and infer CNN classifier"
      ],
      "metadata": {
        "id": "_UpzJnPSwGtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import some important libraries"
      ],
      "metadata": {
        "id": "90FQdrAuxAVY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YrJFvf0yhQLD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Drive"
      ],
      "metadata": {
        "id": "4zHerJ7SxGqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "twJSqkJohUct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making train and test Transforms"
      ],
      "metadata": {
        "id": "ZGvivTc5xKm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((32,32)),\n",
        "    #transforms.RandomHorizontalFlip(p = 0.25),\n",
        "    #transforms.RandomRotation(10), #10 degree rotation\n",
        "    transforms.ToTensor(),# necessary for pytorch\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    #transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n"
      ],
      "metadata": {
        "id": "ddxvd3QIhdV3"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "glWQY5e8hgn4"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4"
      ],
      "metadata": {
        "id": "I4pqqltNhkmk"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creat train and test data Loader"
      ],
      "metadata": {
        "id": "IeimyRLFxR8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset_path = \"./drive/MyDrive/training/training\""
      ],
      "metadata": {
        "id": "9jGhuaSjhqY5"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_dataset_path = './drive/MyDrive/validation/validation'"
      ],
      "metadata": {
        "id": "BAQKsrqqhsaW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Ds =torchvision.datasets.ImageFolder(root = training_dataset_path, transform = train_transforms)\n",
        "Test_Ds =torchvision.datasets.ImageFolder(root = testing_dataset_path, transform = test_transforms)"
      ],
      "metadata": {
        "id": "fMNBygNWhvoz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = Train_Ds, batch_size = 4, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = Test_Ds, batch_size = 4, shuffle = False)"
      ],
      "metadata": {
        "id": "zKdgyxdWh6G5"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes"
      ],
      "metadata": {
        "id": "WYUBXcIIxZ9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "0FmBgE8bh9cH"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a Neural Network"
      ],
      "metadata": {
        "id": "SwcXAcDdxe-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "CQ-mFelNiErd"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()"
      ],
      "metadata": {
        "id": "CbHXQHYsiHKW"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define optimizer and Loss function"
      ],
      "metadata": {
        "id": "Xqh9DXV6xmnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "m7Ji6QLSiKcW"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start Training of CNN"
      ],
      "metadata": {
        "id": "TZKKjROXxvkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "id": "8pM7IOs6iNVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model information"
      ],
      "metadata": {
        "id": "Gw-PRll_x2zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './drive/MyDrive/bestModel_final2.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "07HPGIoSiSaF"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RIYbeEk4qLEz"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load saved model"
      ],
      "metadata": {
        "id": "awoLgMGkyAFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "GWNFFXHYp9ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "WmSme0CSsOIo"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(images)\n"
      ],
      "metadata": {
        "id": "WEq3JR54rspK"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check model accuracy on Validation dataset"
      ],
      "metadata": {
        "id": "ya04wLSYyLgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the  test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "Y0n89z0Ir7pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference of learned model on single image"
      ],
      "metadata": {
        "id": "B2lNzB-xugkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"k\"\n",
        "]"
      ],
      "metadata": {
        "id": "jPDidDpor8Tv"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_transforms = transforms.Compose([\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.ToTensor(),# necessary for pytorch\n",
        "])"
      ],
      "metadata": {
        "id": "VbDf8cHquloy"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "IH-q7UD2vJkQ"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier(model, images_transforms, image_path, classes):\n",
        "  model = model.eval()\n",
        "  image = Image.open(image_path)\n",
        "  image = images_transforms(image).float()\n",
        "  image = image.unsqueeze(0)\n",
        "\n",
        "  output = model(image)\n",
        "  _, predicted = torch.max(output.data, 1)\n",
        "  print(classes[predicted.item()])"
      ],
      "metadata": {
        "id": "fMcWUKVVuyRI"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(net, images_transforms, \"./drive/MyDrive/validation/validation/n1/n100.jpg\", classes)\n"
      ],
      "metadata": {
        "id": "OvZi2RYTu73K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SpoUm1f6vgRZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}